"""
MkDocs hooks for post-build image optimization.
Converts PNG, JPG, and JPEG images to WebP format and updates HTML references.
"""

import os
import re
import shutil
from pathlib import Path
from PIL import Image


def on_pre_build(config):
    """Hook called before the build starts."""
    pass


def fix_html_references(config):
    """
    Fix HTML references to images and other assets that were moved.
    Updates src and href attributes to point to new paths.
    Handles both absolute and relative path references.
    Also fixes numbered folder names within paths (e.g., images/3-folder/).
    """
    site_dir = Path(config['site_dir'])
    path_mappings = config.get('path_mappings', {})
    
    if not path_mappings:
        print("[Path Fixing] No path changes detected, skipping HTML reference updates")
        return
    
    print(f"[Path Fixing] Updating HTML references for {len(path_mappings)} moved files...")
    
    # Build comprehensive replacement patterns
    # Include relative paths (../) variants
    replacement_patterns = {}
    for old_path, new_path in path_mappings.items():
        # Direct path
        replacement_patterns[old_path] = new_path
        
        # With leading slash
        replacement_patterns['/' + old_path] = '/' + new_path
        
        # With relative prefix ../
        replacement_patterns['../' + old_path] = '../' + new_path
        replacement_patterns['../../' + old_path] = '../../' + new_path
        replacement_patterns['../../../' + old_path] = '../../../' + new_path
    
    html_files = list(site_dir.rglob('*.html'))
    updated_files = 0
    total_replacements = 0
    
    for html_path in html_files:
        try:
            content = html_path.read_text(encoding='utf-8')
            original_content = content
            
            # Update references for each pattern
            for old_pattern, new_pattern in replacement_patterns.items():
                # Try different attribute formats
                replacements = [
                    (f'src="{old_pattern}"', f'src="{new_pattern}"'),
                    (f'href="{old_pattern}"', f'href="{new_pattern}"'),
                    (f"src='{old_pattern}'", f"src='{new_pattern}'"),
                    (f"href='{old_pattern}'", f"href='{new_pattern}'"),
                ]
                
                for old_attr, new_attr in replacements:
                    if old_attr in content:
                        content = content.replace(old_attr, new_attr)
                        total_replacements += 1
            
            # Additional pass: Fix numbered folder names within paths
            # Pattern: /\d+-[a-z-]+/ anywhere in src/href attributes
            def clean_numbered_paths(match):
                """Remove numeric prefixes from path segments."""
                attr_name = match.group(1)
                full_path = match.group(2)
                
                # Clean each segment
                segments = full_path.split('/')
                cleaned_segments = [re.sub(r'^\d+-', '', seg) for seg in segments]
                cleaned_path = '/'.join(cleaned_segments)
                
                return f'{attr_name}="{cleaned_path}"'
            
            # Apply pattern to src and href attributes
            new_content = re.sub(
                r'((?:src|href))="([^"]*\d+-[^"]*)"',
                clean_numbered_paths,
                content
            )
            
            if new_content != content:
                content = new_content
                total_replacements += 1
            
            # Write back if changed
            if content != original_content:
                html_path.write_text(content, encoding='utf-8')
                updated_files += 1
                
        except Exception as e:
            print(f"[Path Fixing] Failed to update {html_path}: {e}")
    
    print(f"[Path Fixing] Updated {updated_files} HTML files ({total_replacements} references)")


def generate_htaccess(config):
    """
    Generate .htaccess file with redirects for renamed URLs.
    Handles both trailing slash and no trailing slash cases.
    """
    site_dir = Path(config['site_dir'])
    url_redirects = config.get('url_redirects', {})
    
    if not url_redirects:
        print("[Redirects] No URL changes detected, skipping .htaccess generation")
        return
    
    htaccess_path = site_dir / '.htaccess'
    
    htaccess_content = """# Auto-generated redirects for URL structure changes
# Generated by MkDocs hooks.py

RewriteEngine On
RewriteBase /

# Redirect old numbered paths to clean paths
"""
    
    # Sort redirects for cleaner output and track rules
    rule_count = 0
    for old_url, new_url in sorted(url_redirects.items()):
        # Strip leading slash for RewriteRule
        old_pattern = old_url.lstrip('/').rstrip('/')
        new_target = new_url.lstrip('/').rstrip('/')
        
        # Add redirect rule for path with trailing slash
        htaccess_content += f'RewriteRule ^{re.escape(old_pattern)}/$ /{new_target}/ [R=301,L]\n'
        rule_count += 1
        
        # Add redirect rule for path without trailing slash
        htaccess_content += f'RewriteRule ^{re.escape(old_pattern)}$ /{new_target}/ [R=301,L]\n'
        rule_count += 1
    
    htaccess_path.write_text(htaccess_content)
    print(f"[Redirects] Generated .htaccess with {rule_count} redirect rules")


def rename_output_directories(config):
    """
    Physically rename output directories to remove numbered prefixes.
    This ensures all file paths are consistent.
    Note: With the on_files hook working correctly, this function may find
    no directories to rename as MkDocs creates them with clean names.
    """
    site_dir = Path(config['site_dir'])
    
    # Find all directories with numbered prefixes
    renamed_count = 0
    
    # Walk from deepest to shallowest to avoid path conflicts
    all_dirs = sorted([d for d in site_dir.rglob('*') if d.is_dir()], 
                     key=lambda x: len(x.parts), reverse=True)
    
    # Count how many have numbered prefixes
    numbered_dirs = [d for d in all_dirs if re.match(r'^\d+-', d.name)]
    
    if numbered_dirs:
        print(f"[Directory Renaming] Found {len(numbered_dirs)} numbered directories to rename")
        
        for dir_path in numbered_dirs:
            dir_name = dir_path.name
            
            # Remove the prefix
            new_name = re.sub(r'^\d+-', '', dir_name)
            new_path = dir_path.parent / new_name
            
            # Rename if target doesn't exist
            if not new_path.exists():
                dir_path.rename(new_path)
                renamed_count += 1
            else:
                # Merge directories if target exists
                for item in dir_path.iterdir():
                    target = new_path / item.name
                    if item.is_file():
                        shutil.move(str(item), str(target))
                    elif item.is_dir():
                        if target.exists():
                            shutil.rmtree(target)
                        shutil.move(str(item), str(target))
                dir_path.rmdir()
                renamed_count += 1
        
        print(f"[Directory Renaming] Renamed {renamed_count} directories")
    else:
        print("[Directory Renaming] No numbered directories found (on_files hook successfully created clean paths)")


def convert_images_to_webp(config):
    """
    Convert all PNG, JPG, and JPEG images to WebP format and update HTML references.
    Tracks conversion statistics and updates all HTML files with new WebP paths.
    """
    site_dir = Path(config['site_dir'])
    
    print("\n[WebP Conversion] Starting image conversion...")
    
    # Track conversion statistics
    stats = {
        'converted': 0,
        'skipped': 0,
        'failed': 0,
        'total_original_size': 0,
        'total_webp_size': 0
    }
    
    # Find all images to convert
    image_extensions = ('.png', '.jpg', '.jpeg')
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(site_dir.rglob(f'*{ext}'))
    
    # Also check for existing WebP files to track skipped conversions
    existing_webp = set()
    for webp_file in site_dir.rglob('*.webp'):
        existing_webp.add(webp_file.stem)
    
    print(f"[WebP Conversion] Found {len(image_files)} images to process, {len(existing_webp)} WebP files already exist")
    
    # Convert each image to WebP
    conversion_map = {}  # Maps old path to new WebP path
    
    for img_path in image_files:
        try:
            webp_path = img_path.with_suffix('.webp')
            
            # Skip if WebP already exists and is newer than source
            # This handles incremental builds
            if webp_path.exists():
                webp_mtime = webp_path.stat().st_mtime
                img_mtime = img_path.stat().st_mtime
                
                if webp_mtime >= img_mtime:
                    # WebP is up to date, skip conversion
                    stats['skipped'] += 1
                    webp_size = webp_path.stat().st_size
                    stats['total_webp_size'] += webp_size
                    
                    # Still add to conversion map for HTML updates
                    old_rel_path = img_path.relative_to(site_dir).as_posix()
                    new_rel_path = webp_path.relative_to(site_dir).as_posix()
                    conversion_map[old_rel_path] = new_rel_path
                    
                    # Remove original image
                    img_path.unlink()
                    continue
            
            # Get original file size
            original_size = img_path.stat().st_size
            stats['total_original_size'] += original_size
            
            # Convert to WebP
            with Image.open(img_path) as img:
                # Convert RGBA to RGB if necessary (for JPEG compatibility)
                if img.mode in ('RGBA', 'LA', 'P'):
                    # Create white background
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
                    img = background
                
                # Save as WebP with quality 85 (good balance between size and quality)
                img.save(webp_path, 'WEBP', quality=85, method=6)
            
            # Get WebP file size
            webp_size = webp_path.stat().st_size
            stats['total_webp_size'] += webp_size
            
            # Calculate savings
            savings_percent = ((original_size - webp_size) / original_size) * 100 if original_size > 0 else 0
            
            # Store mapping for HTML updates (relative to site_dir)
            old_rel_path = img_path.relative_to(site_dir).as_posix()
            new_rel_path = webp_path.relative_to(site_dir).as_posix()
            conversion_map[old_rel_path] = new_rel_path
            
            stats['converted'] += 1
            
            if stats['converted'] % 50 == 0:
                print(f"[WebP Conversion] Processed {stats['converted']}/{len(image_files)} images...")
            
            # Remove original image file
            img_path.unlink()
            
        except Exception as e:
            print(f"[WebP Conversion] Failed to convert {img_path}: {e}")
            stats['failed'] += 1
    
    # Update HTML files to reference WebP images
    if conversion_map:
        print(f"[WebP Conversion] Updating HTML references...")
        html_files = list(site_dir.rglob('*.html'))
        updated_files = 0
        total_replacements = 0
        
        for html_path in html_files:
            try:
                content = html_path.read_text(encoding='utf-8')
                original_content = content
                file_updated = False
                
                # Update image references - replace file extensions directly
                for old_path, new_path in conversion_map.items():
                    # Extract just the filename for simpler matching
                    old_filename = Path(old_path).name
                    new_filename = Path(new_path).name
                    
                    # Replace in src attributes
                    if old_filename in content:
                        new_content = content.replace(f'src="{old_path}"', f'src="{new_path}"')
                        
                        # Also handle relative paths - just replace the filename
                        new_content = new_content.replace(old_filename, new_filename)
                        
                        if new_content != content:
                            replacements = content.count(old_filename)
                            total_replacements += replacements
                            content = new_content
                            file_updated = True
                
                # Write back if changed
                if file_updated and content != original_content:
                    html_path.write_text(content, encoding='utf-8')
                    updated_files += 1
                    
            except Exception as e:
                print(f"[WebP Conversion] Failed to update {html_path}: {e}")
        
        print(f"[WebP Conversion] Updated {updated_files} HTML files ({total_replacements} image references)")
    
    # Print summary statistics
    print(f"\n[WebP Conversion] Summary:")
    print(f"  - Images converted: {stats['converted']}")
    print(f"  - Images skipped (already converted): {stats['skipped']}")
    print(f"  - Conversion failures: {stats['failed']}")
    
    if stats['total_original_size'] > 0 or stats['total_webp_size'] > 0:
        original_mb = stats['total_original_size'] / (1024 * 1024)
        webp_mb = stats['total_webp_size'] / (1024 * 1024)
        savings_mb = original_mb - webp_mb
        savings_percent = (savings_mb / original_mb) * 100
        
        print(f"  - Original size: {original_mb:.2f} MB")
        print(f"  - WebP size: {webp_mb:.2f} MB")
        print(f"  - Space saved: {savings_mb:.2f} MB ({savings_percent:.1f}%)")
    
    print("[WebP Conversion] Complete!\n")


def on_post_build(config):
    """
    Hook called after the build completes.
    Orchestrates all post-build operations:
    - Directory renaming (remove numbered prefixes)
    - HTML reference fixing
    - .htaccess redirect generation
    - WebP image conversion (skipped in serve mode for performance)
    """
    import sys
    import os
    
    # Always rename output directories (needed for correct serving)
    rename_output_directories(config)
    
    # Always fix HTML references (needed for correct links)
    fix_html_references(config)
    
    # Always generate .htaccess redirects
    generate_htaccess(config)
    
    # Skip WebP conversion in serve/livereload mode for performance
    # Check if we're running mkdocs serve or if MKDOCS_SKIP_WEBP env var is set
    if 'serve' in sys.argv or os.environ.get('MKDOCS_SKIP_WEBP'):
        print("[WebP Conversion] Skipping conversion in livereload mode (use 'mkdocs build' for WebP conversion)")
        return
    
    # Convert images to WebP format
    convert_images_to_webp(config)


def on_files(files, config):
    """
    Rename files and folders to remove prefix numbers from the final URL paths.
    Keeps the numeric prefix in the source for sorting, but removes it from output.
    Tracks old->new mappings for redirect generation.
    """
    url_redirects = {}  # Maps old URL to new URL
    path_mappings = {}  # Maps old paths to new paths for all files
    
    for file in files:
        # Skip root index.md to avoid permission issues
        if file.src_path == 'index.md':
            continue
            
        # Process all files in the docs directory
        if file.src_path:
            parts = file.src_path.split('/')
            new_parts = []
            changed = False
            
            # Process each path segment (folders and filename)
            for part in parts:
                # Check if this segment starts with digits followed by dash
                cleaned_part = re.sub(r'^\d+-', '', part)
                if cleaned_part != part:
                    changed = True
                new_parts.append(cleaned_part)
            
            # Only process if something changed
            if not changed:
                continue
            
            # Build new destination path - same logic for all file types
            new_dest_path = '/'.join(new_parts)
            
            # For markdown files, adjust to folder/index.html structure
            if file.src_path.endswith('.md'):
                filename = new_parts[-1].replace('.md', '')
                if filename == 'index':
                    new_dest_path = '/'.join(new_parts[:-1])
                    if new_dest_path:
                        new_dest_path += '/index.html'
                    else:
                        new_dest_path = 'index.html'
                else:
                    new_dest_path = '/'.join(new_parts[:-1] + [filename, 'index.html'])
            
            # Store old values for redirect mapping
            old_dest_uri = file.dest_uri
            old_url = file.url
            
            # Track path mapping for all files (for fixing references)
            path_mappings[old_dest_uri] = new_dest_path
            
            # Update file destination and URL
            file.dest_uri = new_dest_path
            
            # Update dest_path if it exists (some MkDocs versions use this)
            if hasattr(file, 'dest_path'):
                file.dest_path = new_dest_path
            
            # Update URL for markdown files
            if file.src_path.endswith('.md'):
                # Calculate new URL
                new_url = '/' + new_dest_path.replace('/index.html', '/')
                
                # Normalize URL
                if new_url.endswith('//'):
                    new_url = new_url[:-1]
                
                # Update file URL
                file.url = new_url
                
                # Track redirect mapping
                old_url_clean = '/' + old_dest_uri.replace('/index.html', '/')
                if old_url_clean.endswith('//'):
                    old_url_clean = old_url_clean[:-1]
                    
                if old_url_clean != new_url:
                    url_redirects[old_url_clean] = new_url
    
    # Store redirects and path mappings in config for use in on_post_build
    config['url_redirects'] = url_redirects
    config['path_mappings'] = path_mappings
    
    return files



